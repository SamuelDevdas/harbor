# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░
# ▒█░▒█ ░█▀▀█ ▒█▀▀█ ▒█▀▀█ ▒█▀▀▀█ ▒█▀▀█
# ▒█▀▀█ ▒█▄▄█ ▒█▄▄▀ ▒█▀▀▄ ▒█░░▒█ ▒█▄▄▀
# ▒█░▒█ ▒█░▒█ ▒█░▒█ ▒█▄▄█ ▒█▄▄▄█ ▒█░▒█
# ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░

# Harbor Configuration.
# ---------------------
# This section contains environment variables that are
# used in Harbor's compose files, configs and can be modified via harbor CLI.

HARBOR_HUGGINGFACE_CACHE="~/.cache/huggingface"
HARBOR_LLAMACPP_CACHE="~/.cache/llama.cpp"
HARBOR_OLLAMA_CACHE="~/.ollama"

# webui
HARBOR_WEBUI_HOST_PORT=33801

# llamacpp
HARBOR_LLAMACPP_HOST_PORT=33831
HARBOR_LLAMACPP_MODEL_SPECIFIER="--hf-repo bartowski/Hermes-2-Theta-Llama-3-8B-GGUF --hf-file Hermes-2-Theta-Llama-3-8B-Q8_0.gguf"
HARBOR_LLAMACPP_EXTRA_ARGS=""

# ollama
HARBOR_OLLAMA_HOST_PORT=33821

# litellm
HARBOR_LITELLM_HOST_PORT=33841

# lmdeploy
HARBOR_LMDEPLOY_HOST_PORT=33831

# searxng
HARBOR_SEARXNG_HOST_PORT=33811

# tgi (text-generation-inference)
HARBOR_TGI_HOST_PORT=33851
HARBOR_TGI_MODEL_SPECIFIER="--model-id hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4 --quantize awq"

# tts (openedai-sppech)
HARBOR_TTS_HOST_PORT=33861
HARBOR_TTS_HOME="voices"
HARBOR_TTS_VOICES_FOLDER="./tts/voices"
HARBOR_TTS_CONFIG_FOLDER="./tts/config"

# ============================================
# Service Configuration.
# You can specify any of the service's own environment variables here.
# ============================================

# Open WebUI
# See https://docs.openwebui.com/getting-started/env-configuration/ for reference.
# --------------------------------------------
WEBUI_NAME=Harbor